<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.7.4">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2019-10-09T19:07:41-04:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Yukun Chen</title><subtitle>Welcome! I'll be posting explanations of projects, and various notes that I find useful and interesting!</subtitle><entry><title type="html">Variational Autoencoder</title><link href="http://localhost:4000/project/2019/03/03/Variational-Autoencoder.html" rel="alternate" type="text/html" title="Variational Autoencoder" /><published>2019-03-03T00:00:00-05:00</published><updated>2019-03-03T00:00:00-05:00</updated><id>http://localhost:4000/project/2019/03/03/Variational-Autoencoder</id><content type="html" xml:base="http://localhost:4000/project/2019/03/03/Variational-Autoencoder.html">&lt;h1 id=&quot;variational-autoencoder&quot;&gt;Variational Autoencoder&lt;/h1&gt;
&lt;h2 id=&quot;about-this-project&quot;&gt;About this Project&lt;/h2&gt;
&lt;p&gt;Here is a simple implementation of a VAE using tensorflow.&lt;/p&gt;

&lt;p&gt;The parameters to be tuned can be accessed in params.py. Analysis below used these parameters.&lt;/p&gt;

&lt;p&gt;The purpose of this repository is to learn and test an understanding of VAES. Please see the &lt;em&gt;VAE background&lt;/em&gt; section, this will get us an understanding of VAEs, which we can then test. See the &lt;em&gt;Analysis&lt;/em&gt; section for an analysis of the VAE.&lt;/p&gt;

&lt;h2 id=&quot;vae-background&quot;&gt;VAE background&lt;/h2&gt;
&lt;h3 id=&quot;resources&quot;&gt;Resources&lt;/h3&gt;
&lt;p&gt;These are great resources for VAEs:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Original Paper: &lt;a href=&quot;https://arxiv.org/abs/1312.6114&quot;&gt;Auto-Encoding Variational Bayes&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Explanation: &lt;a href=&quot;https://arxiv.org/abs/1606.05908&quot;&gt;Tutorial on Variational Autoencoders&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;theory&quot;&gt;Theory&lt;/h3&gt;
&lt;h4 id=&quot;what-is-a-latent-space&quot;&gt;What is a latent space?&lt;/h4&gt;
&lt;p&gt;This is the representation defined by the bottleneck layer of the network. This representation is called the latent representation, which is used to generate the observable data, X.&lt;/p&gt;

&lt;p&gt;The latent space is just the continuous set of all these latent representations.&lt;/p&gt;

&lt;h4 id=&quot;how-does-vaes-construct-a-latent-space&quot;&gt;How does VAEs construct a latent space?&lt;/h4&gt;
&lt;p&gt;Here is the problem: Train on a single point won’t give good results for the points around that point. If we were to just deterministically backprop the difference (as is what happens with a normal autoencoder), we might not get good results when sampling the parts of the space that aren’t training data representations.&lt;/p&gt;

&lt;p&gt;To solve this, we should train a region around X for a given point X. Using the information in X to shape a region in space. Using many of these X will allow us to create our space. The region between two training points will be an interpolation between the two points.&lt;/p&gt;

&lt;p&gt;Another desireable of our space is if we can cause a small region in our space to generate the desired data, as we get further from this region, generation of X becomes more unlikely. This will allow us to use the information within the data efficiently.&lt;/p&gt;

&lt;p&gt;How do we implement this solution? We will have our latent representation be a distribution instead of a deterministic point or a dirac delta. When training, we can update the parameters in this distribution.&lt;/p&gt;

&lt;p&gt;How do we choose a distribution? The standard distribution to choose would be the normal distribution (this is what the paper uses). No matter what the image distribution is (for a given X), our encoder neural network should be able to map the distribution to a normal, (this is our prior). See Figure 2 in &lt;a href=&quot;https://arxiv.org/abs/1606.05908&quot;&gt;Tutorial on Variational Autoencoders&lt;/a&gt;. We can represent the bottleneck layer as a distribution by calculating the mean and standard deviation.&lt;/p&gt;

&lt;p&gt;Prevent the distribution from collapsing to a point! Even if we set up our network to be able to represent a probabilistic latent representation, there is nothing preventing the network from setting the standard deviation to zero. Nothing in our objective accounts for the space between training samples. We need to constrain our latent representation distribution. This is where the KL divergence regularization term comes in. We will constrain it be close to our prior. We try to minimize the KL divergence between the prior (which is an isotropic normal) an our calculated distribution. By doing this we have also forced the images generated to be anchored to the same distribution/region of space (centered around 0), which is what we also desired.&lt;/p&gt;

&lt;h3 id=&quot;implementation-tricks&quot;&gt;Implementation Tricks&lt;/h3&gt;
&lt;p&gt;reparameterization trick:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;What is it?
    &lt;ul&gt;
      &lt;li&gt;We won’t be able to backprop through a random variable. This means that we won’t be able to update the inference model, as our latent representation will be a random variable.&lt;/li&gt;
      &lt;li&gt;The reparameterization trick aims to solve this by separating the deterministic part and the random part. We can have mean and standard deviation be deterministic, where we can back propogate through, and have a noise term which get mulitplied to the standard deviation, which will cause this to be random.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;How to code it? We need to constrain our standard deviation to be positive, since our KL loss depends on that. We can either apply a softplus to the stddev, or we can allow it to be negative and say that the network is calculating the natural log of the stddev, which is what this project does.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;analysis&quot;&gt;Analysis:&lt;/h2&gt;
&lt;h3 id=&quot;ae-vs-vae&quot;&gt;AE vs VAE&lt;/h3&gt;
&lt;p&gt;To first test out our theory, lets look at the difference between an autoencoder and a Variational Auto Encoder.&lt;/p&gt;

&lt;p&gt;It should be easy to switch between the two of them, if we were to just leave out the KL divergence term, we will only be fitting the training data, with dirac deltas, as we are setting X=f(X) (which defines a single point, X). This means that we can expect very good reconstruction, but very poor generation. VAEs will have equal, or worse reconstruction than this, as they are optimizing for a region in space. So, our VAE loss will be bounded by our AE loss. After a bit of testing, we can see that our AE loss is 0.004 (MSE).&lt;/p&gt;

&lt;h3 id=&quot;problem-with-the-learned-representations&quot;&gt;Problem with the learned representations.&lt;/h3&gt;

&lt;p&gt;When converting our network from a AE to a VAE, we start to see a problem. The KLD loss becomes 0! This causes the posterior distribution to be equal to the prior, which will generate the same image every time!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/vae_images/MSE_0.jpg&quot; alt=&quot;Mean Squared Error and KL Loss&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The loss for the reconstruction is being overshadowed by the KLD loss (regularization loss). We should then, increase the KLD loss slowly, give the reconstruction loss some time to re-adjust.&lt;/p&gt;

&lt;p&gt;We put a weight parameter on the KLD term:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;wait until model reached sufficent reconstruction quality, then increase the weight by a fraction at each step, cap at 1.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This problem called posterior collapse. The model makes predictions independent of the latent representation, and will therefore try to solely minimize the regularization term instead. This causes the posterior to become equal to our prior, all our training representations collapse down to the same distribution.&lt;/p&gt;

&lt;p&gt;To solve this &lt;a href=&quot;https://arxiv.org/pdf/1511.06349.pdf&quot;&gt;Bowman et al.&lt;/a&gt; mention in section 3.1 that they increase the KLD loss slowly from 0 to 1, called KLD annealing.&lt;/p&gt;

&lt;p&gt;Section 2.2 of &lt;a href=&quot;https://arxiv.org/pdf/1611.02731.pdf&quot;&gt;Chen et al.&lt;/a&gt; mention that posterior collapse is caused by an expressive decoder, where the decoder could sufficiently model x without z. They look at this using a &lt;a href=&quot;https://www.cs.helsinki.fi/u/ahonkela/papers/infview.pdf&quot;&gt;bits-back&lt;/a&gt; approach.&lt;/p&gt;

&lt;h3 id=&quot;model-architecture&quot;&gt;Model Architecture&lt;/h3&gt;
&lt;p&gt;the architecture that I used for this loss training:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Encoder: 2x Conv Layers, [64,4,2], 1x fully connected layer [256]&lt;/li&gt;
  &lt;li&gt;Latent Space Size: 32&lt;/li&gt;
  &lt;li&gt;Decoder: 1x Conv Layer [64,4,2], 1x Conv Layer [1,4,2], 1x fully connected layer [256]&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Additionally I used a batch size of 64&lt;/p&gt;

&lt;h3 id=&quot;autoencoder-analysis&quot;&gt;Autoencoder Analysis&lt;/h3&gt;

&lt;p&gt;Let’s first analyze a VAE with the KLD weight set to 0, just as an initial test to see if our model can run on the data. We need to see if the model has the capacity to learn the data.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/vae_images/AE_0.gif&quot; alt=&quot;Autoencoder Training Samples. Smaller pixel values were increased, to make them more prominent.&quot; /&gt;
&lt;img src=&quot;/assets/vae_images/AE_0_analysis.jpg&quot; alt=&quot;Autoencoder Training Values, The upper and lower bounds are the highest and lowest values in the test batch for their repective labels (ie. mean and stddev).&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Here, we see that the theory above is correct. We see from how the images evolve, that the model is capable of learning the images. Notice how the standard deviation of the latent variables are being minimized to 0.&lt;/p&gt;

&lt;p&gt;Since our model is not constrained, the goal of the model is to directly minimize the loss from the training samples, and thus has poor generation abilities. Mathematically, this is shown from the mean and standard deviation of the latent variables, which can be see as interpolations, or a bridge between the control points of the training samples. The model tries to minimize the effect each item has on one another, causing the increase in mean and the decrease in standard deviation.&lt;/p&gt;

&lt;h3 id=&quot;kld-annealing&quot;&gt;KLD Annealing&lt;/h3&gt;

&lt;p&gt;Now, lets try KLD annealing mentioned before. We can slowly increase the regularization term weight, while letting the reconstruction catch up. The rate of increase will be done empirically (through experiments). We can start increasing the weight after a while of letting the reconstruction term learn in an AE manner first (weight=0), to get a foothold.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/vae_images/AE_1.gif&quot; alt=&quot;Autoencoder Training Samples with KLD Annealing. Smaller pixel values were increased, to make them more prominent.&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/vae_images/AE_1_analysis.jpg&quot; alt=&quot;Autoencoder Training Values with KLD Annealing, The upper and lower bounds are the highest and lowest values in the test batch for their repective labels (ie. mean and stddev).&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Here we can see that the generation results are better, and the reconstruction results seem to be less grainy as well, which might be an effect of using information from other, similar training points. This might be an effect of compression, where good representations are being forced to be learned to minimize the space due to the constraint (regularization term). However, over training, it seems like the numbers are noiser, this is probably due to the effect of the increase in the standard deviation term, causing more noise to be added (it is not being minimized to 0 now.). We can see how much more constrained the distributions of the latent variables are now. The ranges for the mean is smaller, where as the standard deviations are larger now.&lt;/p&gt;

&lt;h3 id=&quot;decreasing-model-capacity&quot;&gt;Decreasing Model Capacity&lt;/h3&gt;

&lt;p&gt;Another reason on why posterior collapse would happen is due to the decoder having high capacity. We can test this out by simply decreasing the capacity of the VAE.&lt;/p&gt;

&lt;p&gt;Convolutional neural networks have the assumption of invariance to position built into the achitecture through the sliding window (kernel). This means that it won’t have to learn this quality of the data. Normal neural networks perform worse, since they need sufficient data and model capacity to be able to learn this feature. Therefore, we should be able to decrease model capacity by introducing a normal feed forward neural network as the encoder and decoder.&lt;/p&gt;

&lt;p&gt;The architecture I used was:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;a two 500 unit hidden layer feed forward neural net for the encoder with relu activations.&lt;/li&gt;
  &lt;li&gt;a one 500 unit hidden layer feed forward neural net for the decoder with relu activation.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/vae_images/VAE_0.gif&quot; alt=&quot;Variational Autoencoder Training Samples with low capacity. Smaller pixel values were increased, to make them more prominent.&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/vae_images/VAE_0_analysis.jpg&quot; alt=&quot;Variarional Autoencoder Training Values with low capacity, The upper and lower bounds are the highest and lowest values in the test batch for their repective labels (ie. mean and stddev).&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This method seems more stable. We see that in the beginning the images start to all look similar and the KLD loss is approaching 0, representative of mode collapse. However, after a bit of training, the model is able to regain good representations. This seems much more stable than a high capacity network.&lt;/p&gt;</content><author><name></name></author><summary type="html">Variational Autoencoder About this Project Here is a simple implementation of a VAE using tensorflow.</summary></entry><entry><title type="html">ESLII Chapter 3 Reference</title><link href="http://localhost:4000/reference/2019/01/16/ESLII-Chapter-3-Reference.html" rel="alternate" type="text/html" title="ESLII Chapter 3 Reference" /><published>2019-01-16T00:00:00-05:00</published><updated>2019-01-16T00:00:00-05:00</updated><id>http://localhost:4000/reference/2019/01/16/ESLII-Chapter-3-Reference</id><content type="html" xml:base="http://localhost:4000/reference/2019/01/16/ESLII-Chapter-3-Reference.html">&lt;h1 id=&quot;reference-for-eslii-chapter-3&quot;&gt;Reference for ESLII Chapter 3&lt;/h1&gt;
&lt;p&gt;Here is the reference for chapter which includes explanations, and definitions for chapter 3 of &lt;em&gt;The Elements of Statistical Learning&lt;/em&gt;.&lt;/p&gt;

&lt;h3 id=&quot;-eyx-is-linear-in-the-inputs&quot;&gt;&lt;a id=&quot;linear_in_inputs&quot;&gt;&lt;/a&gt; E(Y|X) is linear in the inputs:&lt;/h3&gt;
&lt;p&gt;Linear in the inputs mean that there is a direct linear correlation between X and Y. A transformation of your input data, X can be used directly as components of Y.&lt;/p&gt;

&lt;p&gt;What this means is that, the combinations of your parameters $\beta$ end up becoming linear. Remember that your parameters are numerical representations of the relationship between your X and Y.&lt;/p&gt;</content><author><name></name></author><summary type="html">Reference for ESLII Chapter 3 Here is the reference for chapter which includes explanations, and definitions for chapter 3 of The Elements of Statistical Learning.</summary></entry><entry><title type="html">ESLII Chapter 2 Reference</title><link href="http://localhost:4000/reference/2018/12/23/ESLII-Chapter-2-Reference.html" rel="alternate" type="text/html" title="ESLII Chapter 2 Reference" /><published>2018-12-23T00:00:00-05:00</published><updated>2018-12-23T00:00:00-05:00</updated><id>http://localhost:4000/reference/2018/12/23/ESLII-Chapter-2-Reference</id><content type="html" xml:base="http://localhost:4000/reference/2018/12/23/ESLII-Chapter-2-Reference.html">&lt;h1 id=&quot;reference-for-eslii-chapter-2&quot;&gt;Reference for ESLII Chapter 2&lt;/h1&gt;
&lt;p&gt;Here is the reference for chapter which includes explanations, and definitions for chapter 2 of &lt;em&gt;The Elements of Statistical Learning&lt;/em&gt;.&lt;/p&gt;

&lt;h3 id=&quot;affine-set&quot;&gt;&lt;a id=&quot;affine_set&quot;&gt;&lt;/a&gt;Affine Set&lt;/h3&gt;
&lt;p&gt;An affine set is a continuous set/space of points, similar to a &lt;a href=&quot;#convex_set&quot;&gt;convex set&lt;/a&gt;, but rather than just including the line segment in between the two point, an affine set includes the points on the line, if both ends of the straight line was extended to infinity. So rather than including the points on just a infinite or finite segment, it includes the points on an infinite line. (convex sets can be infinite as well as finite. Affine sets are only finite.)&lt;/p&gt;

&lt;p&gt;Check out &lt;a href=&quot;https://www.quora.com/What-the-relationship-between-affine-set-and-convex-set&quot;&gt;this Quora answer&lt;/a&gt; or &lt;a href=&quot;https://math.stackexchange.com/questions/88750/convexity-and-affineness&quot;&gt;this stackexchange answer&lt;/a&gt; for information on affine vs convex sets.&lt;/p&gt;

&lt;h3 id=&quot;convex-set&quot;&gt;&lt;a id=&quot;convex_set&quot;&gt;&lt;/a&gt;Convex Set&lt;/h3&gt;
&lt;p&gt;A convex set is a region of space, where given any 2 points in that region/set, if we were to draw a straight line segment connecting the two points, every point on that line should be in the convex set as well. This means that regions that look line a “U” are not convex since you can pick out two points (eg. on the tail ends of the U) where the line inbetween is not included in the set.&lt;/p&gt;

&lt;p&gt;For more information watch &lt;a href=&quot;https://www.youtube.com/watch?v=VcTIOQpRG1o&quot;&gt;this youtube video&lt;/a&gt;!&lt;/p&gt;

&lt;h3 id=&quot;how-does-emathbinverty---fxmathbinvert-end-up-being-the-medianyxx&quot;&gt;&lt;a id=&quot;l1_to_median&quot;&gt;&lt;/a&gt;How does $E\mathbin{\vert}Y - f(X)\mathbin{\vert}$ end up being the median($Y$|$X=x$)?&lt;/h3&gt;
&lt;p&gt;Lets look at this closely. $Y - f(X)$ is the error of your model.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;If this error was squared (L2 error)&lt;/em&gt;: then larger errors for a point x_l, will be weighted more than smaller errors by a given point x_s. A small shift in $f(x)$ towards the larger error point will reduce the error by much more than a shift of the same amount towards that small error point. This means that the model will be biased towards solving the larger errors first. Which might be what you want, but this also means that outliers could be a huge problem. Also, if you wanted to build a model high in variance, this loss might cause constrain that (Eg. Generative models for art. You wouldn’t want the same art piece to be generated each time.)&lt;/p&gt;

&lt;p&gt;However &lt;em&gt;if we used the abolute of this error (L1 error)&lt;/em&gt;: then shifts towards larger values will decrease the error by the same amount as shifts towards the smaller values. This will cause us to find some sort of equilibrium at the median of the datapoints, where if you shifted your prediction up, the error of the points below would increase, while the points above would decrease, and vice versa for a shift downwards. This will be much more helpful with regards to outliers.&lt;/p&gt;

&lt;p&gt;I highly suggest drawing out a numberline with a few points and finding the minimum absolute error to prove that it will be the median.&lt;/p&gt;

&lt;p&gt;check out &lt;a href=&quot;https://stats.stackexchange.com/questions/34613/l1-regression-estimates-median-whereas-l2-regression-estimates-mean&quot;&gt;this stack exchage answer&lt;/a&gt; for more information.&lt;/p&gt;

&lt;h3 id=&quot;structural-assumptions&quot;&gt;&lt;a id=&quot;structural_assumptions&quot;&gt;&lt;/a&gt;Structural Assumptions&lt;/h3&gt;
&lt;p&gt;Structural assumptions assumptions made about the global relationship between all x and y. For Example, linear relationship.&lt;/p&gt;

&lt;p&gt;We make these assumptions to decrease the amount of data, as you won’t need to use the data to determine what the structure is.&lt;/p&gt;

&lt;p&gt;Another reason we make these assumptions, is that our prediction could be more accurate if our assumptions are correct. We will see this later in Chapter 2.5 (Figure 2.7, 2.8)&lt;/p&gt;

&lt;h3 id=&quot;voronoi-tessellationvoronoi-diagrams&quot;&gt;&lt;a id=&quot;voronoi_tessellation&quot;&gt;&lt;/a&gt;Voronoi Tessellation/Voronoi Diagrams&lt;/h3&gt;
&lt;p&gt;There are the splitting of space into different regions, based on distance to the closest point. This is similar to a decision boundary for each point in kNN. &lt;a href=&quot;https://en.wikipedia.org/wiki/Voronoi_diagram&quot;&gt;Seeing a picture&lt;/a&gt; would help.&lt;/p&gt;

&lt;h3 id=&quot;minimizing-pointwise&quot;&gt;&lt;a id=&quot;minimizing_pointwise&quot;&gt;&lt;/a&gt;Minimizing &lt;em&gt;pointwise&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;Minimizing pointwise means minimizing, given the samples that we have, as opposed to the whole $X$ distribution (which we don’t have). So basically, just minimizing over our training set. The effect that this would have on the equations is $X$ becomes $X=x$ where we give it the training set of x.&lt;/p&gt;

&lt;h3 id=&quot;robustness&quot;&gt;&lt;a id=&quot;robust&quot;&gt;&lt;/a&gt;Robustness&lt;/h3&gt;
&lt;p&gt;For a model to be “robust” in this case means, how much an outlier can affect your model. We would want to know this as if a single data point can heavily influence our model, we would either need to introduce more datapoints, or do more work to ensure the data is cleaned.&lt;/p&gt;

&lt;h3 id=&quot;curse-of-dimensionality&quot;&gt;&lt;a id=&quot;curse_of_dimensionality&quot;&gt;&lt;/a&gt;Curse Of Dimensionality&lt;/h3&gt;
&lt;p&gt;The amount of data that we need increases exponentially as the amount of dimensions in the input. As the dimensionality increases, the amount of space that the model has to adjust to increases. Why would we want to increase the dimensionality? Remember that we can see the dimensionality as being more features that we can define our output with, thus, if our training set sufficiently represents the true distribution, we could possibly have features that would decrease the error/uncertainty in our output. (Possibly, since the features might be orthogonal to the output.)&lt;/p&gt;</content><author><name></name></author><summary type="html">Reference for ESLII Chapter 2 Here is the reference for chapter which includes explanations, and definitions for chapter 2 of The Elements of Statistical Learning.</summary></entry></feed>